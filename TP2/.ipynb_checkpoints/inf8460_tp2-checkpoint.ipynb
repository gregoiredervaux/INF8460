{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# École Polytechnique de Montréal\n",
    "Département Génie Informatique et Génie Logiciel\n",
    "INF8460 – Traitement automatique de la langue naturelle\n",
    "\n",
    "### Prof. Amal Zouaq\n",
    "### Chargé de laboratoire: Félix Martel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF8460 - TP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "•\tExplorer les modèles d’espaces vectoriels comme représentations distribuées de la sémantique des mots et des documents\n",
    "\n",
    "•\tComprendre différentes mesures de distance entre vecteurs de documents et de mots\n",
    "\n",
    "•\tUtiliser un modèle de langue n-gramme de caractères et l’algorithme Naive Bayes pour l’analyse de sentiments dans des revues de films (positives, négatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données est séparé en deux répertoires `train/`et `test`, chacun contenant eux-mêmes deux sous-répertoires `pos/` et `neg/` pour les revues positives et négatives. Un fichier `readme` décrit plus précisément les données.\n",
    "\n",
    "Commencez par lire ces données, en gardant séparées les données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "dictionnaire = {\n",
    "    \"test\": {\"pos\": {},\n",
    "            \"neg\": {}},\n",
    "    \"train\": {\"pos\": {},\n",
    "            \"neg\": {}}\n",
    "}\n",
    "for train_type in [\"test\", \"train\"]:\n",
    "    for classification in [\"pos\", \"neg\"]:\n",
    "        path = './data/' + train_type + '/' + classification + '/'\n",
    "        for file in os.listdir(path):\n",
    "            id_review, rate_review = file.split(\"_\")\n",
    "            rate_review = rate_review.split(\".txt\")[0]\n",
    "            if int(id_review) not in dictionnaire[train_type][classification]:\n",
    "                with open(path + file, \"r\") as f:\n",
    "                    dictionnaire[train_type][classification][int(id_review)] = { \"rate\": int(rate_review),\n",
    "                                                                            \"review\": f.read()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Créez la fonction `clean_doc()` qui effectue les pré-traitements suivants : segmentation en mots ; \n",
    "suppression des signes de ponctuations ; suppression des mots qui contiennent des caractères autres qu’alphabétiques ; \n",
    "suppression des mots qui sont connus comme des stop words ; suppression des mots qui ont une longueur de 1 caractère. Ensuite, appliquez-la à vos données.\n",
    "\n",
    "Les stop words peuvent être obtenus avec `from nltk.corpus import stopwords`. Vous pourrez utiliser des [expressions régulières](https://docs.python.org/3.7/howto/regex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**\tCréez la fonction `build_voc()` qui extrait les unigrammes de l’ensemble d’entraînement et conserve ceux qui ont une fréquence d’occurrence de 5 au moins et imprime le nombre de mots dans le vocabulaire. Sauvegardez-le dans un fichier `vocab.txt` (un mot par ligne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Vous devez créer une fonction `get_top_unigrams(n)` qui retourne les $n$ unigrammes les plus fréquents et les affiche, puis l'appeler avec $n=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)**\tVous devez créer une fonction `get_top_unigrams_per_cls(n, cls)` qui retourne les $n$ unigrammes les plus fréquents de la classe `cls` (pos ou neg) et les affiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)**\tAffichez les 10 unigrammes les plus fréquents dans la classe positive :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)**\tAffichez les 10 unigrammes les plus fréquents dans la classe négative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrices de co-occurence\n",
    "\n",
    "Pour les matrices de cette section, vous pourrez utiliser [des array `numpy`](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html) ou des DataFrame [`pandas`](https://pandas.pydata.org/pandas-docs/stable/). \n",
    "\n",
    "Ressources utiles :  le [*quickstart tutorial*](https://numpy.org/devdocs/user/quickstart.html) de numpy et le guide [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Matrice document × mot et TF-IDF\n",
    "\n",
    "\n",
    "Soit $X \\in \\mathbb{R}^{m \\times n}$ une matrice de $m$ documents et $n$ mots, telle que $X_{i,j}$ contient la fréquence d'occurrence du terme $j$ dans le document $i$ :\n",
    "\n",
    "$$\\textbf{rowsum}(X, d) = \\sum_{j=1}^{n}X_{dj}$$\n",
    "\n",
    "$$\\textbf{TF}(X, d, t) = \\frac{X_{d,t}}{\\textbf{rowsum}(X, d)}$$\n",
    "\n",
    "$$\\textbf{IDF}(X, t) = \\log\\left(\\frac{m}{|\\{d : X_{d,t} > 0\\}|}\\right)$$\n",
    "\n",
    "$$\\textbf{TF-IDF}(X, d, t) = \\textbf{TF}(X, d, t) \\cdot \\textbf{IDF}(X, t)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant le même vocabulaire de 5 000 unigrammes, vous devez représenter les documents dans une matrice de co-occurrence document × mot $M(d, w)$  et les pondérer avec la mesure TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Matrice mot × mot et PPMI (*positive pointwise mutual information*)\n",
    "\n",
    "Vous devez calculer la métrique PPMI. Pour une matrice $m \\times n$ $X$ :\n",
    "\n",
    "\n",
    "$$\\textbf{colsum}(X, j) = \\sum_{i=1}^{m}X_{ij}$$\n",
    "\n",
    "$$\\textbf{sum}(X) = \\sum_{i=1}^{m}\\sum_{j=1}^{n} X_{ij}$$\n",
    "\n",
    "$$\\textbf{expected}(X, i, j) = \n",
    "\\frac{\n",
    "  \\textbf{rowsum}(X, i) \\cdot \\textbf{colsum}(X, j)\n",
    "}{\n",
    "  \\textbf{sum}(X)\n",
    "}$$\n",
    "\n",
    "\n",
    "$$\\textbf{pmi}(X, i, j) = \\log\\left(\\frac{X_{ij}}{\\textbf{expected}(X, i, j)}\\right)$$\n",
    "\n",
    "$$\\textbf{ppmi}(X, i, j) = \n",
    "\\begin{cases}\n",
    "\\textbf{pmi}(X, i, j) & \\textrm{if } \\textbf{pmi}(X, i, j) > 0 \\\\\n",
    "0 & \\textrm{otherwise}\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**\tA partir des textes du corpus d’entrainement (neg *et* pos), vous devez construire une matrice de co-occurrence mot × mot $M(w,w)$ qui contient les 5000 unigrammes les plus fréquents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**\tVous devez créer une fonction `calculate_PPMI` qui prend la matrice $M(w,w)$ et la transforme en une matrice $M’(w,w)$ avec les valeurs PPMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mesures de similarité\n",
    "\n",
    "En utilisant le module [scipy.spatial.distance](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html),  définissez des fonctions pour calculer les métriques suivantes :\n",
    "\n",
    "**Distance Euclidienne**\n",
    "\n",
    "La distance euclidienne entre deux vecteurs $u$ et $v$ de dimension $n$ est\n",
    "\n",
    "$$\\textbf{euclidean}(u, v) = \n",
    "\\sqrt{\\sum_{i=1}^{n}|u_{i} - v_{i}|^{2}}$$\n",
    "\n",
    "En deux dimensions, cela correspond à la longueur de la ligne droite entre deux points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Implémentez la fonction `get_euclidean_distance(v1 ,v2)` qui retourne la distance euclidienne entre les vecteurs v1 et v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance Cosinus**\n",
    "\n",
    "\n",
    "La distance cosinus entre deux vecteurs $u$ et $v$ de dimension $n$ s'écrit :\n",
    "\n",
    "$$\\textbf{cosine}(u, v) = \n",
    "1 - \\frac{\\sum_{i=1}^{n} u_{i} \\cdot v_{i}}{\\|u\\|_{2} \\cdot \\|v\\|_{2}}$$\n",
    "\n",
    "Le terme de droite dans la soustraction mesure l'angle entre $u$ et $v$; on l'appelle la *similarité cosinus* entre $u$ et $v$.\n",
    "\n",
    "**b)** Implémentez la fonction `get_cosinus_distance(v1, v2)` qui retourne la distance cosinus entre les vecteurs v1 et v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Implémentez la fonction `get_most_similar_PPMI(word, metric, n)` qui prend un mot en entrée et une mesure de distance et qui retourne les n mots les plus similaires selon la mesure. Les mesures à tester sont : la distance euclidienne et la distance cosinus implantées ci-dessus. Le vecteur du mot word doit être extrait de la matrice $M’(w,w)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Trouvez les 5 mots les plus similaires au mot « bad » et affichez-les, pour chacune des deux distances. Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-> Commentez ici<-*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Implémentez la fonction `get_most_similar_TFIDF(word, metric, n)` qui prend un mot en entrée et une mesure de distance et qui retourne les n mots les plus similaires selon la mesure. Les mesures à tester sont : la distance euclidienne et la distance cosinus implantées ci-dessus. Le vecteur du mot word doit être extrait de la matrice $M(d,w)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Trouvez les 5 mots les plus similaires au mot « bad » et affichez-les, pour chacune des deux distances. Commentez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-> Commentez ici <-*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification de documents avec un modèle de langue\n",
    "\n",
    "En vous inspirant de [cet article](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139), entraînez deux modèles de langue $n$-gramme de caractère avec lissage de Laplace, l'un sur le corpus `pos`, l'autre sur le corpus `neg`. Puis, pour chaque document $D$, calculez sa probabilité selon vos deux modèles : $P(D \\mid \\textrm{pos})$ et $P(D \\mid \\textrm{neg})$.\n",
    "\n",
    "Vous pourrez alors prédire sa classe $\\hat{c}_D \\in (\\textrm{pos}, \\textrm{neg})$ en prenant :\n",
    "\n",
    "$$\\hat{c}_D = \\begin{cases}\n",
    "\\textrm{pos} & \\textrm{si } P(D \\mid \\textrm{pos}) > P(D \\mid \\textrm{neg}) \\\\\n",
    "\\textrm{neg} & \\textrm{sinon}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification de documents avec sac de mots et Naive Bayes\n",
    "\n",
    "Ici, vous utiliserez l'algorithme Multinomial Naive Bayes (disponible dans [`sklearn.naive_bayes.MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)) pour classifier les documents. Vous utiliserez un modèle sac de mots (en anglais *bag of words*, ou BoW) avec TF-IDF pour représenter vos documents.\n",
    "\n",
    "*Note :* vous avez déjà construit la matrice TF-IDF à la section 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Améliorations\n",
    "\n",
    "Ici, vous devez proposer une méthode d'amélioration pour le modèle précédent, la justifier et l'implémenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-> Écrivez vos explications ici <-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Évaluation\n",
    "\n",
    "Évaluation des modèles des sections 4, 5, 6 sur les données de test. On attend les métriques suivantes : *accuracy*, et pour chaque classe précision, rappel, score F1. Vous pourrez utiliser le module [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentez vos résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-> Commentez ici vos résultats <-*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
